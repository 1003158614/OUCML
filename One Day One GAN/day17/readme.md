# Self-Supervised Generative Adversarial Networks 

## Abstract

cGAN处于自然图像合成的最前沿。这种模型的主要缺点是标记数据的必要性。在这项工作中，我们利用两种流行的无监督学习技术（对抗性训练和自我监督）来缩小有条件和无条件GAN之间的差距。自监督的作用是鼓励判别器学习有意义的特征表示，这些表示在训练期间不会被遗忘。

## A Key Issue:Discriminator Forgetting

传统的GAN的核心公式为：

![1554727641089](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\1554727641089.png)

每当生成器G的参数发生变化时，判别器也会发生变化，这意味着判别器是非平稳的在线学习

在非凸函数的在线学习中，神经网络已被证明会忘记先前的任务，在GAN的背景下，学习不同级别的细节，结构和纹理可以被认为是不同的任务。因此，训练中不稳定的一个原因是，只要当前表示对分类有用，就不会激励判别器维持有用的数据表示。

作者在论文中设计实验来证明了特征的遗忘，如下图(a)所示：

![1554730058072](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\1554730058072.png)

分类器被训练用1 vs all的方式在CIFAR10数据集的十个类别上进行训练，在每个任务上训练1k次，10k以后回到原点，根据图像我们可以发现，每次任务切换时，分类器精度都会大幅下降。在10k次迭代之后，任务循环重复，并且精度与第一个循环相同，即没有任何有用的信息在任务中传递。(b)中加入的自监督，我们可以发现其准确率是在逐渐提升的。

GAN的情况与此类似，如下图：

![1554730758943](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\1554730758943.png)

在训练期间，无条件GAN的准确率增加，然后减少，表明有关分类的信息被获取并随后被遗忘。这种遗忘与训练不稳定性有关。添加自我监督可以防止在鉴别器表示中遗忘这些类。

## The Self-Supervised GAN

在判别器遗忘的主要挑战的推动下，我们的目标是为鉴别器注入一种机制，允许学习有用的表示，而不依赖于当前生成器的质量。 为此，我们利用自监督的表示学习方法的最新进展。 自监督背后的主要思想是在预测任务上训练模型，如预测图像块的旋转角度或相对位置，然后从结果网络中提取相关表示。

作者应用了基于图像旋转的最先进的自监督方法， 在该方法中，旋转图像，并且旋转角度变为人造标签。 然后，自监督的任务是预测图像的旋转角度。直观地，这种损失促使分类器学习有用的图像表示以检测旋转角度，并转移到图像分类任务。

![1554731701345](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\1554731701345.png)

加入自监督以后的损失函数为：

![1554731800972](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\1554731800972.png)

![1554732560588](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\1554732560588.png)

生成器和判别器在真实与假预测损失方面是对抗的，然而，它们在旋转任务方面是协作的。生成器不是有条件的，而是仅生成“直立”图像，随后将其旋转并馈送到判别器。另一方面，训练判别器仅基于真实数据检测旋转角度。换句话说，判别器的参数仅基于真实数据上的旋转损失而更新。鼓励生成器生成可旋转检测的图像，因为它们与用于旋转分类的真实图像共享特征。

## Experiments

![1554732962702](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\1554732962702.png)



