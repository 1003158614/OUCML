## 工作报告10.14-MARCUS



## 时间：2019.10.14~2019.10.21



## 待完成事项

> 很多
>
> 

## 周一



### 代码



### paper

>#  GANPaint Studio
>
>#### Semantic Photo Manipulation with a Generative Image Prior
>
>[David Bau](https://people.csail.mit.edu/davidbau/home/), [Hendrik Strobelt](http://hendrik.strobelt.com/), [William Peebles](https://www.linkedin.com/in/william-peebles-a980a212a/), [Jonas Wulff](https://scholar.google.com/citations?user=ft85d8kAAAAJ&hl=en), [Bolei Zhou](http://bzhou.ie.cuhk.edu.hk/), [Jun-Yan Zhu](https://people.csail.mit.edu/junyanz/), [Antonio Torralba](http://web.mit.edu/torralba/www/)
>
>GANPaint Studio is a starting point to show how creative tools in the future could work. The tool takes a natural image of a specific category, e.g. churches or kitchen, and allows modifications with brushes that do not just draw simple strokes, but actually draw semantically meaningful units – such as trees, brick-texture, or domes. This is a joined project by researchers from MIT CSAIL, IBM Research, and the [MIT-IBM Watson AI Lab](https://mitibmwatsonailab.mit.edu/). Enjoy playing with it.
>
>
>
>[Try the demo](http://ganpaint.io/demo/) [Paper (SIGGRAPH 2019)](http://ganpaint.io/#paper)





### 知乎好文



### 工作时间



### 每日小结



## 周二

### 代码



### paper

https://github.com/creafz/pytorch-cnn-finetune

Fine-tune pretrained Convolutional Neural Networks with PyTorch.





### 知乎好文

(继)pytorch中的pretrain模型网络结构修改:https://blog.csdn.net/whut_ldz/article/details/78874977?utm_source=blogxgwz0







### 工作时间



### 每日小结



## 周三



### 代码



### paper

Shift-Net: Image Inpainting via Deep Feature Rearrangement(ECCV):

>Abstract. Deep convolutional networks (CNNs) have exhibited their
>potential in image inpainting for producing plausible results. However,
>in most existing methods, e.g., context encoder, the missing parts are
>predicted by propagating the surrounding convolutional features through
>a fully connected layer, which intends to produce semantically plausible
>but blurry result. In this paper, we introduce a special shift-connection
>layer to the U-Net architecture, namely Shift-Net, for filling in missing
>regions of any shape with sharp structures and fine-detailed textures.
>To this end, the encoder feature of the known region is shifted to serve
>as an estimation of the missing parts. A guidance loss is introduced on
>decoder feature to minimize the distance between the decoder feature
>after fully connected layer and the ground-truth encoder feature of the
>missing parts. With such constraint, the decoder feature in missing region
>can be used to guide the shift of encoder feature in known region. An
>end-to-end learning algorithm is further developed to train the Shift-Net.
>Experiments on the Paris StreetView and Places datasets demonstrate
>the efficiency and effectiveness of our Shift-Net in producing sharper,
>fine-detailed, and visually plausible results. The codes and pre-trained
>models are available at https://github.com/Zhaoyi-Yan/Shift-Net.
>Keywords: Inpainting · feature rearrangement · deep learning
>
>

### 知乎好文



https://blog.csdn.net/whut_ldz/article/details/78845947

pytorch中的pre-train函数模型引用及修改（增减网络层，修改某层参数等）

>### Supported architectures and models
>
>#### From the [torchvision](https://github.com/pytorch/vision/) package:
>
>- ResNet (`resnet18`, `resnet34`, `resnet50`, `resnet101`, `resnet152`)
>- ResNeXt (`resnext50_32x4d`, `resnext101_32x8d`)
>- DenseNet (`densenet121`, `densenet169`, `densenet201`, `densenet161`)
>- Inception v3 (`inception_v3`)
>- VGG (`vgg11`, `vgg11_bn`, `vgg13`, `vgg13_bn`, `vgg16`, `vgg16_bn`, `vgg19`, `vgg19_bn`)
>- SqueezeNet (`squeezenet1_0`, `squeezenet1_1`)
>- MobileNet V2 (`mobilenet_v2`)
>- ShuffleNet v2 (`shufflenet_v2_x0_5`, `shufflenet_v2_x1_0`)
>- AlexNet (`alexnet`)
>- GoogLeNet (`googlenet`)
>
>#### From the [Pretrained models for PyTorch](https://github.com/Cadene/pretrained-models.pytorch) package:
>
>- ResNeXt (`resnext101_32x4d`, `resnext101_64x4d`)
>- NASNet-A Large (`nasnetalarge`)
>- NASNet-A Mobile (`nasnetamobile`)
>- Inception-ResNet v2 (`inceptionresnetv2`)
>- Dual Path Networks (`dpn68`, `dpn68b`, `dpn92`, `dpn98`, `dpn131`, `dpn107`)
>- Inception v4 (`inception_v4`)
>- Xception (`xception`)
>- Squeeze-and-Excitation Networks (`senet154`, `se_resnet50`, `se_resnet101`, `se_resnet152`, `se_resnext50_32x4d`, `se_resnext101_32x4d`)
>- PNASNet-5-Large (`pnasnet5large`)
>- PolyNet (`polynet`)



### 工作时间



### 每日小结





## 周四

### 代码

pytorch fine-tune:https://github.com/creafz/pytorch-cnn-finetune

Pretrained models for Pytorch (Work in progress):https://github.com/Cadene/pretrained-models.pytorch#pretrained-models-for-pytorch-work-in-progress





### paper



### 知乎好文



### 工作时间



### 每日小结



## 周五

### 代码



### paper



### 知乎好文





### 工作时间



### 每日小结



## 周六

### 代码



### paper



### 知乎好文





### 工作时间



### 每日小结







## 周日

### 代码



### paper





### 知乎好文





### 工作时间



### 每日小结



