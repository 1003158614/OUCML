# 工作报告9.16-MARCU

## 时间：2019.9.16~2019.9.22

新的一周又开始了，耶✌️

## 周一

### 代码

工作计划

```
RSRGAN原始工作--R
补充实验：
R-SN
R-SN+WGAN-GP
R-SA
R-SR+双头Attention
```

### paper

无

### 知乎好文

[几篇较新的计算机视觉Self-Attention](https://zhuanlan.zhihu.com/p/44031466)

### 工作时间

早上上课 4h

下午上课 4h

6-8 健身 2w 步

8-10 点：实验室工作，讨论会议改期刊补充实验，写代码验证补充实验

### 每日小结

没什么时间

## 周二

### 代码

无

### paper

Generate To Adapt Aligning Domains using Generative Adversarial Networks

运用 GAN 实现域适应,可运用于半监督,小样本,域迁移等等,创新性很不错.

Maximum Classifier Discrepancy for Unsupervised Domain Adaptation

把对抗的实现运用到垮域分类问题上,是一篇非常有创新性的工作,cvpr oral 文章非常好.

其原理时候具有创新性.

### 知乎好文

[模块设计之 SKNet, GCNet, GloRe, Octave](https://zhuanlan.zhihu.com/p/65524880)

[AAAI 2019：把Cross Entropy梯度分布拉‘平’，就能轻松超越Focal Loss](https://zhuanlan.zhihu.com/p/55017036)

[ICCV 2019：基于关联语义注意力模型的图像修复](https://zhuanlan.zhihu.com/p/82049019)

### 工作时间

不知道

### 每日小结

主要讨论了接下来一步的每一项工作如何进展.

- cvpr 的工作进展
- ICONIP 收尾工作
- 转投期刊的相关补充实验

## 周三

### 代码

无

### paper

无

### 知乎好文

[常见排序方法总结（python实现）](https://zhuanlan.zhihu.com/p/83148834)

### 工作时间

无

### 每日小结

好像啥都没干,就一整天都在睡觉

## 周四

### 代码

实现了参数化调解的训练代码,

开始收尾 ICONIP的参数测试工作预计 4 天完成对比实验

### paper

无

### 知乎好文

[生成对抗网络GAN如果只训练一个网络会有效果么？](https://www.zhihu.com/question/276070438/answer/825816888)

> 
>
> 但是![[公式]](https://www.zhihu.com/equation?tex=P_r)与![[公式]](https://www.zhihu.com/equation?tex=P_g)不重叠或重叠部分可忽略的可能性有多大？不严谨的答案是：非常大。比较严谨的答案是：**当![[公式]](https://www.zhihu.com/equation?tex=P_r)与![[公式]](https://www.zhihu.com/equation?tex=P_g)的支撑集（support）是高维空间中的低维流形（manifold）时，![[公式]](https://www.zhihu.com/equation?tex=P_r)与![[公式]](https://www.zhihu.com/equation?tex=P_g)重叠部分测度（measure）为0的概率为1。**
>
> **所以其实在实践过程中，用一个很优的判别器去训练好一个网络的概率其实很小。**

### 工作时间

8h

### 每日小结

无

## 周五

### 代码

>提取双头注意力机制的核心代码,为改进 TIP 做进一步的工作.

### paper

没时间看

### 知乎好文

没时间看

### 工作时间

11节课

### 每日小结

很累

## 周六-周日

两天都在胶州参加 CCAI

### 每日小结

一路上很辛苦,看到了目前来说,SR 还有 DN 又火起来了,前沿工作逐渐从2D 转向3D,越来越多的工作似乎已经不再满足2D了,视频和3D 的工作我觉得会逐渐的多起来,但是基础研究还是以 2D 为主,我们要做的还是打好理论基础,先完成手头上的工作吧.

---

## 下一个星期的目标

随着 ICONIP 工作的收尾,接下来我希望能在这个星期也就是国庆节开始之前完成 TIP 转投期刊的实验,这个应该不会特别就,大概就是两个模块的作用的分析,还有就是在创新性上可能考虑把 self

Attention 换成dual Attention ,再进一步的改进其实意义也不是很大,国庆 7 天主要冲击 CVPR 的实验.

开学第一周课程压力还好,现在可能还要兼顾的一点就是英语的学习,cvpr 要尝试开始自己动笔写文章了,以后的路总归是要自己走.